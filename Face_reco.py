# -*- coding: utf-8 -*-
"""ML_Pro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S0fvpxD3FXpcRUhZTkRud2Jk8EEokdXD
"""

!pip install pyheif
!pip install mtcnn
!pip install keras-facenet

import os
import cv2
import numpy as np
import pandas as pd
import pyheif
import matplotlib.pyplot as plt
import plotly.express as px
from PIL import Image
from keras.preprocessing import image
from keras_facenet import FaceNet
from tqdm import tqdm
from keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder

from google.colab import drive
drive.mount('/content/drive')
train_dataset='/content/drive/MyDrive/data/training'
test_dataset='/content/drive/MyDrive/data/testing'
text_file = '/content/drive/MyDrive/data/testing/file_mapping.txt'

root_path = '/content/drive/MyDrive/data/training'

dir_names = os.listdir(root_path)
person_names = [name.split("_")[-1].title() for name in dir_names]
NUM_CLASSES = len(person_names)
n_images_per_person = [len(os.listdir(os.path.join(root_path, name))) for name in dir_names]

print(f"Total number of Students in the class: {NUM_CLASSES}\n")
print(f"Name of the students : \n\t{person_names}")

def count_jpeg_images(dataset_path):
    num_jpeg_images = 0
    for dirpath, _, filenames in os.walk(dataset_path):
        for filename in filenames:
            if filename.lower().endswith(('.jpeg')):
                num_jpeg_images += 1
    return num_jpeg_images

train_num_jpeg_images = count_jpeg_images(train_dataset)
test_num_jpeg_images = count_jpeg_images(test_dataset)

print("Number of JPEG images in training dataset:", train_num_jpeg_images)
print("Number of JPEG images in testing dataset:", test_num_jpeg_images)

from mtcnn.mtcnn import MTCNN
input_directory = "/content/drive/MyDrive/data/training"
output_directory = "/content/cropped"

detector = MTCNN()

for root, dirs, files in os.walk(input_directory):
    for file in files:
        original_file_path = os.path.join(root, file)
        relative_path = os.path.relpath(original_file_path, input_directory)
        output_file_path = os.path.join(output_directory, relative_path)
        output_subdirectory = os.path.dirname(output_file_path)
        if not os.path.exists(output_subdirectory):
            os.makedirs(output_subdirectory)

        image = cv2.imread(original_file_path)
        faces = detector.detect_faces(image)

        if len(faces) > 0:
            x, y, w, h = faces[0]['box']
            cropped_face = image[y:y+h, x:x+w]
            cv2.imwrite(output_file_path, cropped_face)
        else:
            cv2.imwrite(output_file_path, image)
            img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            plt.imshow(img)
            plt.show()
            print(f"No faces found in the image")

print("Processing completed.")

import os
import cv2
import numpy as np
from mtcnn.mtcnn import MTCNN

def augment_cropped_images(input_directory, output_directory):
    if not os.path.exists(output_directory):
        os.makedirs(output_directory)
    detector = MTCNN()
    flip_horizontal = True
    brightness_factors = [0.7, 1.3]
    rotation_angles = [-15, 15]
    for root, dirs, files in os.walk(input_directory):
        for file in files:
            original_file_path = os.path.join(root, file)
            relative_path = os.path.relpath(original_file_path, input_directory)
            output_file_path = os.path.join(output_directory, relative_path)
            output_subdirectory = os.path.dirname(output_file_path)
            if not os.path.exists(output_subdirectory):
                os.makedirs(output_subdirectory)

            image = cv2.imread(original_file_path)
            augmented_images = [image]
            if flip_horizontal:
                flipped_img = cv2.flip(image, 1)
                augmented_images.append(flipped_img)

            for factor in brightness_factors:
                adjusted_img = adjust_brightness(image, factor)
                augmented_images.append(adjusted_img)

            for angle in rotation_angles:
                rotated_img = rotate_image(image, angle)
                augmented_images.append(rotated_img)


            for i, augmented_img in enumerate(augmented_images):
                output_file_path = os.path.join(output_subdirectory, f"{file.split('.')[0]}_{i}.jpg")
                cv2.imwrite(output_file_path, augmented_img)

def adjust_brightness(image, factor):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    hsv[..., 2] = np.clip(hsv[..., 2] * factor, 0, 255)
    adjusted_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
    return adjusted_img

def rotate_image(image, angle):
    height, width = image.shape[:2]
    rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), angle, 1)
    rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))
    return rotated_image

input_directory = "/content/cropped"
output_directory = "/content/augmented"
augment_cropped_images(input_directory, output_directory)

def count_images_in_folder(folder_path):
    count = 0
    for root, dirs, files in os.walk(folder_path):
        count += len(files)
    return count

output_directory = "/content/augmented"
num_images_after_augmentation = count_images_in_folder(output_directory)
print("Number of images after augmentation:", num_images_after_augmentation)

def load_data(directory):
    X = []
    y = []
    for label in os.listdir(directory):
        for filename in os.listdir(os.path.join(directory, label)):
            X.append(os.path.join(directory, label, filename))
            y.append(label)
    return X, y

TRAIN_DIR = '/content/augmented'
train=pd.DataFrame()
train['image'], train['label']=load_data(TRAIN_DIR)
print(train)

from PIL import Image
from keras.preprocessing import image
def extract_features_facenet(images):
    feature_list = []
    model = FaceNet()
    for img_path in tqdm(images):
        img = image.load_img(img_path, target_size=(160, 160))
        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        embeddings = model.embeddings(img_array)
        feature_list.append(embeddings)

    features = np.vstack(feature_list)
    return features

from keras.applications.resnet50 import ResNet50, preprocess_input
from keras.models import Model
from tqdm import tqdm
import numpy as np

def extract_features(images):
    feature_list = []
    base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    model = Model(inputs=base_model.input, outputs=base_model.output)
    for img_path in tqdm(images):
        img = image.load_img(img_path, target_size=(224, 224))
        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = preprocess_input(img_array)
        features = model.predict(img_array)
        feature_list.append(features)
    features = np.vstack(feature_list)
    return features

from keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
train['label'] = train['label'].astype(str).str.replace(" ", "").str.lower()
le = LabelEncoder()
le.fit(train['label'])
y_train_encoded = le.transform(train['label'])
le.classes_

from sklearn.model_selection import train_test_split
train_features = extract_features(train['image'])
x_train, x_test, y_train, y_test = train_test_split(train_features, y_train_encoded, test_size=0.2, random_state=42)
print("X_train shape:", x_train.shape)
print("X_test shape:", x_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

pipeline1 = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=15)),
    ('classifier', SVC(kernel='rbf'))
])

pipeline2 = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=15)),
    ('classifier', KNeighborsClassifier(n_neighbors=5))
])

pipeline3 = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=15)),
    ('classifier', DecisionTreeClassifier())
])

pipeline4 = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=15)),
    ('classifier', GaussianNB())
])
pipeline1.fit(x_train, y_train)
pipeline2.fit(x_train, y_train)
pipeline3.fit(x_train, y_train)
pipeline4.fit(x_train, y_train)
accuracy1 = pipeline1.score(x_test, y_test)
accuracy2 = pipeline2.score(x_test, y_test)
accuracy3 = pipeline3.score(x_test, y_test)
accuracy4 = pipeline4.score(x_test, y_test)
print("SVM Accuracy: {:.2f}%".format(accuracy1 * 100))
print("KNN Accuracy: {:.2f}%".format(accuracy2 * 100))
print("Decision Tree Accuracy: {:.2f}%".format(accuracy3 * 100))
print("Baysian Classifier Accuracy: {:.2f}%".format(accuracy4 * 100))

from sklearn.model_selection import train_test_split
train_features1 = extract_features_facenet(train['image'])
x_train, x_test, y_train, y_test = train_test_split(train_features1, y_train_encoded, test_size=0.2, random_state=42)
print("X_train shape:", x_train.shape)
print("X_test shape:", x_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.svm import SVC

pipeline5 = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=15)),
    ('lda', LDA(n_components=10)),
    ('classifier', SVC(kernel='rbf'))
])

pipeline6 = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=15)),
    ('lda', LDA(n_components=10)),
    ('classifier', KNeighborsClassifier(n_neighbors=5))
])

pipeline7 = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=15)),
    ('lda', LDA(n_components=10)),
    ('classifier', DecisionTreeClassifier())
])

pipeline8 = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=15)),
    ('lda', LDA(n_components=10)),
    ('classifier', GaussianNB())
])
pipeline5.fit(x_train, y_train)
pipeline6.fit(x_train, y_train)
pipeline7.fit(x_train, y_train)
pipeline8.fit(x_train, y_train)
accuracy5 = pipeline5.score(x_test, y_test)
accuracy6 = pipeline6.score(x_test, y_test)
accuracy7 = pipeline7.score(x_test, y_test)
accuracy8 = pipeline8.score(x_test, y_test)
print("SVM Accuracy: {:.2f}%".format(accuracy5 * 100))
print("KNN Accuracy: {:.2f}%".format(accuracy6 * 100))
print("Decision Tree Accuracy: {:.2f}%".format(accuracy7 * 100))
print("Baysian Classifier Accuracy: {:.2f}%".format(accuracy8 * 100))



precision5 = precision_score(y_test, pipeline5.predict(x_test), average='weighted')
recall5 = recall_score(y_test, pipeline5.predict(x_test), average='weighted')
f1_score5 = f1_score(y_test, pipeline5.predict(x_test), average='weighted')

precision6 = precision_score(y_test, pipeline6.predict(x_test), average='weighted')
recall6 = recall_score(y_test, pipeline6.predict(x_test), average='weighted')
f1_score6 = f1_score(y_test, pipeline6.predict(x_test), average='weighted')

precision7 = precision_score(y_test, pipeline7.predict(x_test), average='weighted')
recall7 = recall_score(y_test, pipeline7.predict(x_test), average='weighted')
f1_score7 = f1_score(y_test, pipeline7.predict(x_test), average='weighted')

precision8 = precision_score(y_test, pipeline8.predict(x_test), average='weighted')
recall8 = recall_score(y_test, pipeline8.predict(x_test), average='weighted')
f1_score8 = f1_score(y_test, pipeline8.predict(x_test), average='weighted')


print("SVM Precision: {:.2f}".format(precision5))
print("SVM Recall: {:.2f}".format(recall5))
print("SVM F1 Score: {:.2f}".format(f1_score5))

print("KNN Precision: {:.2f}".format(precision6))
print("KNN Recall: {:.2f}".format(recall6))
print("KNN F1 Score: {:.2f}".format(f1_score6))

print("Decision Tree Precision: {:.2f}".format(precision7))
print("Decision Tree Recall: {:.2f}".format(recall7))
print("Decision Tree F1 Score: {:.2f}".format(f1_score7))

print("Bayesian Classifier Precision: {:.2f}".format(precision8))
print("Bayesian Classifier Recall: {:.2f}".format(recall8))
print("Bayesian Classifier F1 Score: {:.2f}".format(f1_score8))



def is_image_file(filename):
    valid_extensions = ['.jpeg']
    _, extension = os.path.splitext(filename)
    return extension.lower() in valid_extensions
def test_data(directory):
    X = []
    y = []
    for label in os.listdir(directory):
        file_path = os.path.join(directory, label)
        if os.path.isfile(file_path) and is_image_file(file_path):
            X.append(file_path)
            i = imag.index(label)
            y.append(second[i])
    return X, y

test_dir=test_dataset
test= pd.DataFrame()
test['images'],test['labels']=test_data(test_dir)
test

test_dir='/content/drive/MyDrive/data/testing'
tests= pd.DataFrame()
tests['images'],tests['labels']=test_data(test_dir)
print(tests)







